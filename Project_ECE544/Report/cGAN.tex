\subsection{Conditional GAN} \label{cGAN}
We have adopted the CGAN architecture from \cite{pix2pix} to train and test our model. Denoting the input, ground truth, and noise by $x$, $y$, and $z$ respectively, we can write the objective for a conditional GAN where the Generator and discriminator are $G$ and $D$ as
\begin{equation}
\begin{array}{l}
\min_G \max_D \mathcal{V}_{CGAN}(D,G) = \mathbb{E}_{x}(\log(D(x|y)))\\
\, \, \, \,+ \, \, \, \mathbb{E}_{z}(\log(1-D(x,G(x|z)))).
\end{array}
\end{equation}
Here, $D()$ is the score that the discriminator gives for a certain input, and $G(x,z)$ is what the generator tries to generate given the input $x$ and noise vector $z$. The point of having the noise vector, of course, it to avoid the problem of over-fitting. The difference between the standard GAN and the conditional version is that in the latter everything is conditioned to $y$. This $y$ could be anything we want, that adds extra information about what the output $G$ should look like. In our setting, we call $y$ the ground truth, as it contains information of real boundaries of the objects. Given $y$, $D$ tries to maximize its output value when the input is real, and at the same time minimize it when the input is artificially generated by the $G$, the generator. At the same time, the generator tries to generate an image that gets a high score from $D$, motivating it to generate images that are similar to real ones.

It is suggested in [pix2pix] that we can combine generator's task of trying to get a high score from discriminator with a pre-determined loss function, such as $L_1$. That is, one could change the objective to be
\begin{equation}
\begin{array}{l}
\min_G \max_D \mathcal{V}_{CGAN}(D,G) =\\
\mathbb{E}_{x}(\log(D(x|y))) \, \, \, \,+ \, \, \, \mathbb{E}_{z}(\log(1-D(x,G(x|z))))\\
+\,\lambda \, \mathcal{L}_{L_1}(G(x,z)).
\end{array}
\end{equation}

The motivation behind this is to capture the low-frequency information using the $L_1$ loss, and motivate GAN to model high-frequency information, which in our case, will translate to more precision in identifying boundaries.

For the generator, was have adopted the architecture of \cite{unet}, which is an auto-encoder. Similar to most such architectures, U-net consists of a contracting path and an expansive path. The first layer contracting path is made of two successive $3 \times 3$ convolutions followed by a ReLu (rectified linear unit) and a $2 \times 2$ max-pooling layer without overlapping, which shrinks the size of its input by a factor of four. Let us call such a layer a down-sampling layer. This layer is then repeated multiple time, each time doubling the feature channels. The expansive path reverses this process: at each layer, the data is first up-sampled by a factor of two, the filtered with using a $2 \times 2$ window (2 by 2 convolution) halving the number of feature channels. At this point, a cropped version feature maps from the corresponding layer in the contracting path is forwarded to this layer (i.e. for layer $k$, the feature maps from layer $n-k$ are forwarded, assuming a total number of $n$ layers) and are concatenated with the current feature maps. There are two points to be mentioned here; first, the cropping should happen because of the loss of edges that has happened due to successive convolutions. Second, and more importantly, this idea is used as a way to detour the bottleneck layer (the middle layer through which all the information should pass) by creating these skip connections between layers. One reason behind this choice of architecture is that this forwarding encourages the similar structure between the input and the output. Authors in \cite{unet} evaluated this architecture in a biomedical image segmentation problem its idea has, and in \cite{pix2pix}, it was adopted to generate a general translator of high-resolution output images to high resolution input images, which is quite similar to our setting, except that in our problem the input images are not high-resolution.

As for the discriminator, what we need is for the network to be able to identify local structures, in order to capture the properties of local objects (e.g. cars). Since the network is relying on the $L_1$ loss to guarantee the correctness of low-frequency information, it is possible to restrict the discriminator to only penalize structures that occur within a patch window of the image. In other words, the discriminator slides over the image looking at patches of size $n \times n$, and scoring each of them, and finally averaging over all patches to derive the final score. This structure has been dubbed patchGAN \cite{pix2pix}. For our implementation, we chose $n$ to be 70 where the image size was $256 \times 256$.
