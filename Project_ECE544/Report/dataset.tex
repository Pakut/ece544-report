\subsection{Dataset Generation}
As analyzed in section \ref{challenges}, when exploiting the application of deep learning in the new field of radar images, the problem of dataset availability is inevitable. Between the two options of building our own dataset: collecting real radar images through experiments and processing synthesized radar reflection, we have to make a trade-off. Although synthesizing dataset might be the only feasible way to create a big enough training dataset, the compatibility of trained model to real radar images significantly depends on the closeness between synthesized  and real radar reflection. Luckily, the transmission, propagation, and reflection of radar waveform are thoroughly studied and can be precisely modeled and simulated. Furthermore, with the help of advanced electromagnetic simulation softwares such as FEKO we can even model the attenuation and specularity of various objects and surfaces. Therefore, a well-designed radar reflection synthesizing algorithm should be indistinguishable from read radar signal, so it is hopeful that the performance of a cGAN model trained with synthesized radar images should not degrade too much when we use real radar image for testing instead. We are also planning to mixing a smaller number of real radar images with the synthesized dataset for training and find the improvement of cGAN performance with respect to the portion of real and synthesized data.  

The radar image synthesizing process can be further separated into: scene generation, reflector modeling, radar signal simulation, and image processing. The last two steps are more straightforward, while the challenge lies in the first two steps. To generate a realistic scene for autonomous cars, we can refer to the well-established street view datasets of video recording frames, such as the Cityscapes dataset ~\cite{cityscapes}, but because pictures do not contain distance information. 

3D % search for 3D GAN

2D
	Mask R-CNN
		input: radar image
		groundtruth: mask
	pros: large dataset with car truck human 
	cons: No 3D info, no specularity
	3D CAD
		input: contour
		groundtruth:
	pros: small dataset, single element 
	cons: 3D shape info, specularity 


Evaluate the simulation with EM simulation Feko and experimental results.

\iffalse
Millimeter radars transmitter shines a radar waveform, which gets reflected by objects, and the reflected waveform will be received by the receiver. Comparing the transmitted and received radar signal, we can measure Time-of-Flight (ToF), which suggests the round-trip distance between radar and reflectors. Besides, with an array of radar receivers, we can also extract the Direction-of-Arrival (DoA) of the reflected waves. Knowing the distance and angle of reflectors in the space, we can localize them in a polar coordinate. 
\par Due to the resolution limit, every pixel in radar images may correspond to a combination of many nearby point reflectors within the distance and angular bin. Therefore, low resolution radar images appear less informative to human. However, this combination of reflection should still follow certain pattern and can be analyzed to distinguish and infer features of the target object. Especially in the application of self-driving cars, we are mostly interested in vehicle and human targets. They both have very unique shapes and motion patterns. If we train our neural network with the combined reflection from point reflectors with certain distribution, we should be able to classify and map the low resolution pixels to the actually shape of the target. Besides, the specularity of RF prevent us from receiving reflection from all features of the target object, and neural networks can help us infer the shape and location of the entire target by analyzing a time series of incomplete images of the object. For example, if we can pin point the head, chest and legs of a person along the trace of the object motion, we can fill up the rest parts of him in our map. 
\par RF-Pose3D ~\cite{rfpose} ~\cite{rfpose3D} demonstrates Convolutional Neural Network (CNN) that can recreate the human body skeletons by tracking 14 key points. Because CNNs leverage local dependencies in the data, it significantly reduces the total number of weights to be learned. Considering this favorable property of CNN, we are going to implement this model first in our project. In contrast, we will concentrate more on classifying features of vehicles to infer the shape, orientation, and even velocity. We are planning to start with 2D images, which contains the distance and angle of objects within a horizontal plane, then we will try to extend to 3D images.
\fi
