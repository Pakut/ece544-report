\section{Introduction and Project Descriptions} \label{introduction}
Since the past few years, AI-Powered autonomy revolution in the automotive industry has attracted great attention worldwide. It is believed that in the not-too-distant future, fully autonomous vehicles will be the norm rather than the exception, redefining mobility in our daily lives. With deep learning widely applied on sensor data, self-driving cars are able to localize and map objects, understand the environment, and eventually make right decisions. As the most essential task, previous works have demonstrated accurate object detection and classification based on sensor data, but they are limited to LiDARs and cameras. These optical sensors can produce high-resolution images, but they naturally fail in low visibility conditions such as fog, rain, and snow, because light beams are narrower than water droplets and snowflakes ~\cite{snow}. Such fundamental limitation of optical sensors is one of the major roadblocks to achieving the 5th SAE level of full automation ~\cite{SAE}. On the contrary, Radar wave can propagate through small particles, which makes it a possible alternate imaging solution in such inclement weather. Moreover, radar also possesses many other advantageous features. For example, it can directly measure the velocity of vehicles based on the Doppler shift of the reflected signal instead of going through cluster tracking among frames like LiDAR. With this additional real-time speed information of objects, AI can potentially have a better perception than human drivers.

Although the low resolution of traditional automotive radar overshadows its advantages, the advent of mmWave (Millimeter-wave)  technology makes it possible to have a reliable 3D imaging system in inclement weather with relatively higher resolution. Along with good propagation characteristics, mmWave also provides much wider bandwidth and enables miniature antenna arrays, which improve the distance and angle estimation respectively. Previous works has demonstrated sub-centimeter level imaging resolution for short range objects ~\cite{mmWave_SAR}, but the fundamental difference in wavelength between radar (5 mm) and LiDAR (905 nm) cannot be easily overcome. Moreover, radar images are not as readable to non-experts, so in order to convince the automotive industry and general public that mmWave is a reliable imaging solution for autonomous driving, we should try to achieve LiDAR grade images, not only of comparable resolution, but also more perceptually intuitive to people. 

In this project, we propose to develop high-quality and reliable imaging techniques for self-driving cars with mmWave radar. Specifically training neural networks to enhance the low-resolution and unreadable radar images to be similar to the LiDAR point cloud, which has been extensively and successfully used for self-driving perception. Ultimately achieving various crucial vision applications for autonomous vehicles like lane detection, object localization and identification with enhanced radar images only. To do this, we have to overcome challenges analyzed in the following section \ref{challenges}.
 
