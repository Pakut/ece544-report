\section{ Method}
Generative Adverserial Networks (or GANs) \cite{GAN} have been widely used to generate images. The input to these networks can be text \cite{text2pix, text2pix2}, where images are generated according to some text or labels; or images \cite{pix2pix, cGANberkeley, TV-GAN, deraning}, where the network is trying to fill in some missing part of the input image, or translate the image onto another domain. In our case, we are looking to generate images with accurate boundaries using low resolution images with missing parts as input. Conditional GANs have already proven successful in similar settings, such as in \cite{hams, TV-GAN}, where the authors have used thermal images under low light conditions where there some parts of the image are missing to retrieve the human face boundaries and estimate its orientation. Another motivation behind using conditional GANs is that loss functions such as the $L_2$ and $L_1$ (i.e. loss functions that are equal the Euclidean or $L_1$ distance between the input and the output) which are the de facto standard loss function for restoring images render blurry images, which are not suitable for our application as they do not emphasize on boundaries. On the other hand, using conditional GAN, we were be able to motivate the loss function in GAN to learn to focus on the boundaries, by designing the ground to contain information mostly about the boundary of objects, as discussed in more detail the dataset section.
	